{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124e5672",
   "metadata": {},
   "source": [
    "# Custom Chatbot Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a94b3",
   "metadata": {},
   "source": [
    "I have chosen the Wikipedia 2023 dataset. This is in order to address the cut-off date for ChatGPT and enable the chatbot to provide answers from the latter part of the year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d4c5f",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "In the cells below, I am doing all necessary imports. Then I will provide an example query for 2023 (after OpenAI cutoff date) to show, that GPT-3.5 is not able to answer this question without additional data/RAG.\n",
    "\n",
    "I will use the 2023 page from Wikipedia as additional data and clean and tokenize the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d138d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from openai.embeddings_utils import get_embedding, distances_from_embeddings\n",
    "# OpenAI API key\n",
    "openai.api_key = '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'\n",
    "from openai.embeddings_utils import get_embedding, distances_from_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7162e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is impossible to answer this question definitively as it is currently December 2020 and we cannot predict events in the future. December 2023 could potentially see a variety of events depending on global, cultural, and personal circumstances. Some possible events that may occur in December 2023 include holidays, natural disasters, political events, technological advancements, sporting events, scientific discoveries, personal or professional milestones, among others.\n"
     ]
    }
   ],
   "source": [
    "#Original answer without training to show cut-off\n",
    "\n",
    "december_prompt = \"\"\"\n",
    "Question: \"What happened in December 2023?\"\n",
    "Answer:\n",
    "\"\"\"\n",
    "initial_december_answer = openai.Completion.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=december_prompt,\n",
    "    max_tokens=150\n",
    ")[\"choices\"][0][\"text\"].strip()\n",
    "print(initial_december_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c69b83a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Wikipedia page for \"2023\" since OpenAI's models stop in 2020\n",
    "resp = requests.get(\"https://en.wikipedia.org/w/api.php?action=query&prop=extracts&exlimit=1&titles=2023&explaintext=1&formatversion=2&format=json\")\n",
    "\n",
    "# Load page text into a dataframe\n",
    "df = pd.DataFrame()\n",
    "df[\"text\"] = resp.json()[\"query\"][\"pages\"][0][\"extract\"].split(\"\\n\")\n",
    "\n",
    "# Clean up text to remove empty lines and headings\n",
    "df = df[(df[\"text\"].str.len() > 0) & (~df[\"text\"].str.startswith(\"==\"))]\n",
    "\n",
    "# In some cases dates are used as headings instead of being part of the\n",
    "# text sample; adjust so dated text samples start with dates\n",
    "prefix = \"\"\n",
    "for (i, row) in df.iterrows():\n",
    "    # If the row already has \" - \", it already has the needed date prefix\n",
    "    if \" – \" not in row[\"text\"]:\n",
    "        try:\n",
    "            # If the row's text is a date, set it as the new prefix\n",
    "            parse(row[\"text\"])\n",
    "            prefix = row[\"text\"]\n",
    "        except:\n",
    "            # If the row's text isn't a date, add the prefix\n",
    "            row[\"text\"] = prefix + \" – \" + row[\"text\"]\n",
    "df = df[df[\"text\"].str.contains(\" – \")]\n",
    "df.to_csv(\"embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0a595980",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text\n",
      "0    – 2023 (MMXXIII) was a common year starting o...\n",
      "1   The year 2023 saw the decline in severity of t...\n",
      "2    – The Russian invasion of Ukraine and Myanmar...\n",
      "3    – A banking crisis resulted in the collapse o...\n",
      "4    – In the realm of technology, 2023 saw the co...\n",
      "11  January 1 – Croatia adopts the euro and joins ...\n",
      "12  January 5 – The funeral of Pope Benedict XVI i...\n",
      "14  January 8 – The 2023 Beninese parliamentary el...\n",
      "15  January 8 – Following the 2022 Brazilian gener...\n",
      "16  January 9 – Juliaca massacre: At least 18 peop...\n"
     ]
    }
   ],
   "source": [
    "# Check dataframe for correctness\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "acb3a9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>– 2023 (MMXXIII) was a common year starting o...</td>\n",
       "      <td>[0.011595670133829117, -0.03160304203629494, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The year 2023 saw the decline in severity of t...</td>\n",
       "      <td>[0.01554702315479517, 0.038631998002529144, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>– The Russian invasion of Ukraine and Myanmar...</td>\n",
       "      <td>[-0.06633021682500839, 0.005727418232709169, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>– A banking crisis resulted in the collapse o...</td>\n",
       "      <td>[-0.013344909995794296, -0.03087935782968998, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>– In the realm of technology, 2023 saw the co...</td>\n",
       "      <td>[0.026942692697048187, 0.0007336187991313636, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Economics – Claudia Goldin, for her empirical ...</td>\n",
       "      <td>[0.012369903735816479, 0.0376892015337944, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Literature – Jon Fosse, for his innovative pla...</td>\n",
       "      <td>[-0.03743856027722359, 0.016004662960767746, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Peace – Narges Mohammadi, for her works on the...</td>\n",
       "      <td>[0.03361355513334274, -0.00215215515345335, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Physics – Pierre Agostini, Ferenc Krausz &amp; Ann...</td>\n",
       "      <td>[-0.03730954974889755, 0.007431724574416876, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Physiology or Medicine – Katalin Karikó &amp; Drew...</td>\n",
       "      <td>[-0.02551143616437912, -0.01450522243976593, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0     – 2023 (MMXXIII) was a common year starting o...   \n",
       "1    The year 2023 saw the decline in severity of t...   \n",
       "2     – The Russian invasion of Ukraine and Myanmar...   \n",
       "3     – A banking crisis resulted in the collapse o...   \n",
       "4     – In the realm of technology, 2023 saw the co...   \n",
       "..                                                 ...   \n",
       "283  Economics – Claudia Goldin, for her empirical ...   \n",
       "284  Literature – Jon Fosse, for his innovative pla...   \n",
       "285  Peace – Narges Mohammadi, for her works on the...   \n",
       "286  Physics – Pierre Agostini, Ferenc Krausz & Ann...   \n",
       "287  Physiology or Medicine – Katalin Karikó & Drew...   \n",
       "\n",
       "                                            embeddings  \n",
       "0    [0.011595670133829117, -0.03160304203629494, 0...  \n",
       "1    [0.01554702315479517, 0.038631998002529144, 0....  \n",
       "2    [-0.06633021682500839, 0.005727418232709169, 0...  \n",
       "3    [-0.013344909995794296, -0.03087935782968998, ...  \n",
       "4    [0.026942692697048187, 0.0007336187991313636, ...  \n",
       "..                                                 ...  \n",
       "283  [0.012369903735816479, 0.0376892015337944, 0.0...  \n",
       "284  [-0.03743856027722359, 0.016004662960767746, 0...  \n",
       "285  [0.03361355513334274, -0.00215215515345335, 0....  \n",
       "286  [-0.03730954974889755, 0.007431724574416876, -...  \n",
       "287  [-0.02551143616437912, -0.01450522243976593, -...  \n",
       "\n",
       "[210 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate embeddings\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-3-small\"\n",
    "batch_size = 100 #limit batch size\n",
    "embeddings = [] #create empty array for embeddings\n",
    "for i in range(0, len(df), batch_size):\n",
    "    # Send text data to OpenAI model to get embeddings\n",
    "    response = openai.Embedding.create(\n",
    "        input=df.iloc[i:i+batch_size][\"text\"].tolist(),\n",
    "        engine=EMBEDDING_MODEL_NAME\n",
    "    )\n",
    "    \n",
    "    # Add embeddings to list\n",
    "    embeddings.extend([data[\"embedding\"] for data in response[\"data\"]])\n",
    "\n",
    "# Add embeddings list to dataframe\n",
    "df[\"embeddings\"] = embeddings\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "351cd757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to CSV\n",
    "df.to_csv(\"embeddings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae769871",
   "metadata": {},
   "source": [
    "## Custom Query Completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "582f0656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rows_sorted_by_relevance(question, df):\n",
    "    \"\"\"\n",
    "    Function that takes in a question string and a dataframe containing\n",
    "    rows of text and associated embeddings, and returns that dataframe\n",
    "    sorted from least to most relevant for that question\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get embeddings for the question text\n",
    "    question_embeddings = get_embedding(question, engine=EMBEDDING_MODEL_NAME)\n",
    "    \n",
    "    # Make a copy of the dataframe and add a \"distances\" column containing\n",
    "    # the cosine distances between each row's embeddings and the\n",
    "    # embeddings of the question\n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"distances\"] = distances_from_embeddings(\n",
    "        question_embeddings,\n",
    "        df_copy[\"embeddings\"].values,\n",
    "        distance_metric=\"cosine\"\n",
    "    )\n",
    "    \n",
    "    # Sort the copied dataframe by the distances and return it\n",
    "    # (shorter distance = more relevant so we sort in ascending order)\n",
    "    df_copy.sort_values(\"distances\", ascending=True, inplace=True)\n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bce173d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>distances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>December 12 – At the COP28 climate summit in D...</td>\n",
       "      <td>[0.008021525107324123, -0.00411166250705719, 0...</td>\n",
       "      <td>0.558898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>July 23 – The 2023 Cambodian general election ...</td>\n",
       "      <td>[0.023684794083237648, 0.008149438537657261, 0...</td>\n",
       "      <td>0.611542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>September 9 – At the 18th G20 summit in New De...</td>\n",
       "      <td>[-0.02522454410791397, -0.02098342776298523, 0...</td>\n",
       "      <td>0.652751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>November 14–November 17 – President Biden host...</td>\n",
       "      <td>[0.004024468827992678, -0.036472756415605545, ...</td>\n",
       "      <td>0.653991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>August 30 – Following the announcement of incu...</td>\n",
       "      <td>[0.035682860761880875, -0.023306088522076607, ...</td>\n",
       "      <td>0.653996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>March 10 – Silicon Valley Bank, the 16th large...</td>\n",
       "      <td>[-0.0022857997100800276, 0.010135394521057606,...</td>\n",
       "      <td>0.932322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>June 14 – Scientists report the creation of th...</td>\n",
       "      <td>[0.06816432625055313, 0.05519308149814606, 0.0...</td>\n",
       "      <td>0.935130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Literature – Jon Fosse, for his innovative pla...</td>\n",
       "      <td>[-0.03743856027722359, 0.016004662960767746, 0...</td>\n",
       "      <td>0.950807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>December 6 – Google DeepMind releases the Gemi...</td>\n",
       "      <td>[-0.0009106243378482759, 0.03048708103597164, ...</td>\n",
       "      <td>0.963028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>November 2 – The Beatles release \"Now and Then...</td>\n",
       "      <td>[0.008334815502166748, 0.01028506737202406, -0...</td>\n",
       "      <td>0.992279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "261  December 12 – At the COP28 climate summit in D...   \n",
       "176  July 23 – The 2023 Cambodian general election ...   \n",
       "204  September 9 – At the 18th G20 summit in New De...   \n",
       "244  November 14–November 17 – President Biden host...   \n",
       "195  August 30 – Following the announcement of incu...   \n",
       "..                                                 ...   \n",
       "69   March 10 – Silicon Valley Bank, the 16th large...   \n",
       "144  June 14 – Scientists report the creation of th...   \n",
       "284  Literature – Jon Fosse, for his innovative pla...   \n",
       "259  December 6 – Google DeepMind releases the Gemi...   \n",
       "239  November 2 – The Beatles release \"Now and Then...   \n",
       "\n",
       "                                            embeddings  distances  \n",
       "261  [0.008021525107324123, -0.00411166250705719, 0...   0.558898  \n",
       "176  [0.023684794083237648, 0.008149438537657261, 0...   0.611542  \n",
       "204  [-0.02522454410791397, -0.02098342776298523, 0...   0.652751  \n",
       "244  [0.004024468827992678, -0.036472756415605545, ...   0.653991  \n",
       "195  [0.035682860761880875, -0.023306088522076607, ...   0.653996  \n",
       "..                                                 ...        ...  \n",
       "69   [-0.0022857997100800276, 0.010135394521057606,...   0.932322  \n",
       "144  [0.06816432625055313, 0.05519308149814606, 0.0...   0.935130  \n",
       "284  [-0.03743856027722359, 0.016004662960767746, 0...   0.950807  \n",
       "259  [-0.0009106243378482759, 0.03048708103597164, ...   0.963028  \n",
       "239  [0.008334815502166748, 0.01028506737202406, -0...   0.992279  \n",
       "\n",
       "[210 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rows_sorted_by_relevance(\"What happened at the COP 2023?\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8b6e1f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def create_prompt(question, df, max_token_count):\n",
    "    \"\"\"\n",
    "    Given a question and a dataframe containing rows of text and their\n",
    "    embeddings, return a text prompt to send to a Completion model\n",
    "    \"\"\"\n",
    "    # Create a tokenizer that is designed to align with our embeddings\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    \n",
    "    # Count the number of tokens in the prompt template and question\n",
    "    prompt_template = \"\"\"\n",
    "Answer the question based on the context below, and if the question\n",
    "can't be answered based on the context, say \"I don't know\"\n",
    "\n",
    "Context: \n",
    "\n",
    "{}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {}\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    current_token_count = len(tokenizer.encode(prompt_template)) + \\\n",
    "                            len(tokenizer.encode(question))\n",
    "    \n",
    "    context = []\n",
    "    for text in get_rows_sorted_by_relevance(question, df)[\"text\"].values:\n",
    "        \n",
    "        # Increase the counter based on the number of tokens in this row\n",
    "        text_token_count = len(tokenizer.encode(text))\n",
    "        current_token_count += text_token_count\n",
    "        \n",
    "        # Add the row of text to the list if we haven't exceeded the max\n",
    "        if current_token_count <= max_token_count:\n",
    "            context.append(text)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return prompt_template.format(\"\\n\\n###\\n\\n\".join(context), question)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c403f543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question based on the context below, and if the question\n",
      "can't be answered based on the context, say \"I don't know\"\n",
      "\n",
      "Context: \n",
      "\n",
      "December 12 – At the COP28 climate summit in Dubai, a consensus is reached for countries to \"transition away\" from fossil fuels, the first such agreement in the conference's 30-year history. The transition is specifically for energy systems, excluding plastics, transport or agriculture.\n",
      "\n",
      "###\n",
      "\n",
      "March 20 – The Intergovernmental Panel on Climate Change (IPCC) releases the synthesis report of its Sixth Assessment Report on climate change.\n",
      "\n",
      "###\n",
      "\n",
      "November 14–November 17 – President Biden hosts the APEC summit in San Francisco which Chinese president Xi Jinping attends. Both countries at the conclusion of the summit agree to re-open suspended channels of military communications and to cooperate in their fight against climate change.\n",
      "\n",
      "---\n",
      "\n",
      "Question: What happened at COP28?\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(create_prompt(\"What happened at COP28?\", df, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "74280b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETION_MODEL_NAME = \"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "def answer_question(\n",
    "    question, df, max_prompt_tokens=1800, max_answer_tokens=150\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a question, a dataframe containing rows of text, and a maximum\n",
    "    number of desired tokens in the prompt and response, return the\n",
    "    answer to the question according to an OpenAI Completion model\n",
    "    \n",
    "    If the model produces an error, return an empty string\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = create_prompt(question, df, max_prompt_tokens)\n",
    "    \n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model=COMPLETION_MODEL_NAME,\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_answer_tokens\n",
    "        )\n",
    "        return response[\"choices\"][0][\"text\"].strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38b36b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1783f146",
   "metadata": {},
   "source": [
    "## Custom Performance Demonstration\n",
    "\n",
    "TODO: In the cells below, demonstrate the performance of your custom query using at least 2 questions. For each question, show the answer from a basic `Completion` model query as well as the answer from your custom query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11fdc0",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4901c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2023 Israeli judicial reform protests erupted across Israel in December.\n"
     ]
    }
   ],
   "source": [
    "custom_2023_answer_1 = answer_question(\"Tell me an example of what happened in December 2023 ?\", df)\n",
    "print(custom_2023_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bd7a093b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am an AI language model and do not have access to real-time information or the ability to predict the future, so I am unable to give a specific example of an event that may happen in December 2023.\n"
     ]
    }
   ],
   "source": [
    "december_prompt_1 = \"\"\"\n",
    "Question: \"Tell me an example of what happened in December 2023?\"\n",
    "Answer:\n",
    "\"\"\"\n",
    "initial_december_answer_1 = openai.Completion.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=december_prompt_1,\n",
    "    max_tokens=150\n",
    ")[\"choices\"][0][\"text\"].strip()\n",
    "print(initial_december_answer_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e86e37c",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f646989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dubai\n"
     ]
    }
   ],
   "source": [
    "custom_2023_answer_2 = answer_question(\"Where was COP28 held this year? ?\", df)\n",
    "print(custom_2023_answer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "11c07a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COP28 (Conference of Parties 28), also known as the United Nations Climate Change Conference, was originally scheduled to be held in Glasgow, Scotland in November 2020. However, due to the COVID-19 pandemic, it had to be postponed and eventually took place virtually from 1-12 November 2021.\n"
     ]
    }
   ],
   "source": [
    "december_prompt_2 = \"\"\"\n",
    "Question: \"Where was COP28 held this year?\"\n",
    "Answer:\n",
    "\"\"\"\n",
    "initial_december_answer_2 = openai.Completion.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=december_prompt_2,\n",
    "    max_tokens=150\n",
    ")[\"choices\"][0][\"text\"].strip()\n",
    "print(initial_december_answer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008f1cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
